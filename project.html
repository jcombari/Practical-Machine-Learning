Proyecto de Aprendizaje Automático Práctica
Resumen de objetivo
En este proyecto está utilizando dispositivos como la quijada para arriba, Nike FuelBand y Fitbit ahora es posible recoger una gran cantidad de datos sobre la actividad del personal relativamente poco costosa. Este tipo de dispositivos son parte del ser cuantificado movimiento - un grupo de entusiastas que toman mediciones sobre sí mismos regularmente para mejorar su salud, para encontrar patrones en su comportamiento, o porque son geeks. Una cosa que la gente regularmente hacen es cuantificar qué parte de una actividad particular que hacen, pero que rara vez se cuantifica lo bien que lo hacen.

En este proyecto, su objetivo será utilizar los datos de los acelerómetros en el cinturón, antebrazo, brazo y dumbell de 6 participantes. Se les pidió que realizar barra ascensores correcta e incorrectamente de 5 maneras diferentes. Más información está disponible en la página web aquí: http://groupware.les.inf.puc-rio.br/har

Nota: Los datos para este proyecto provienen de esta fuente: http://groupware.les.inf.puc-rio.br/har .

Bibliotecas utilizados en este proyecto

biblioteca ( cursor )
## Cargando requerida paquete: celosía
## Cargando paquete necesario: ggplot2
biblioteca ( rpart ) 
biblioteca ( rpart.plot ) 
biblioteca ( RColorBrewer ) 
biblioteca ( sonajero )
## Rattle: Una interfaz gráfica libre para la minería de datos con R.
## Versión 3.3.0 Derechos de Autor (c) 2006-2014 Togaware Pty Ltd.
## 'Sonajero ()' Escriba agitar para, sacudir y rotar SUS Datos.
biblioteca ( randomForest )
## RandomForest 4,6-10
## Tipo rfNews () para ver las nuevas revisiones de características / cambios / errores.
Cargando conjuntos de datos
setwd ( "C: / Coursera / Aprendizaje Automático Práctica" )

formación  <-  read.csv ( "PML-training.csv" , na.strings = c ( "NA" , "# DIV / 0!" , "" ) )
{R, echo = FALSO} dim (formación) `` `

prueba  <-  read.csv ( "PML-testing.csv" , na.strings = c ( "NA" , "# DIV / 0!" , "" ) )
{R, echo = FALSO} dim (pruebas)

#El Conjunto de entrenamiento consta de 19.622 observaciones de las variables 160
#El Conjunto de pruebas consta de 20 observaciones de las variables 160
-El Conjunto de entrenamiento consta de 19.622 observaciones de las variables 160

-El Conjunto de pruebas consta de 20 observaciones de las variables 160

limpieza de datos
Columnas en el entrenamiento y las pruebas de datos orignal que se llenan sobre todo con valores perdidos se retiran entonces contar el número de valores que faltan en cada columna de la formación de datos completa

formación  <- entrenando [ , colSums ( is.na ( entrenamiento ) )  ==  0 ] 
pruebas  <- pruebas [ , colSums ( is.na ( prueba ) )  ==  0 ]
formación    <- formación [ , - c ( 1 : 7 ) ] 
pruebas  <- pruebas [ , - c ( 1 : 7 ) ]

dim  (  entrenamiento  ) 
## [1] 19622 53
dim  (  pruebas   )
## [1] 20 53
cero predictores de varianza
Diagnostica predictores que tienen un valor único (es decir, son cero predictores de varianza) o predictores que son tienen ambas de las siguientes características

ColumnsZVar  <-  nearZeroVar ( training , saveMetrics  =  TRUE ) 
training  <-  training [ , ColumnsZVar $ nzv == FALSE ] 
training $ classe  =  factor ( training $ classe )
El particionado de los datos de entrenamiento Este conjunto de datos de validación nos permitirá realizar la validación cruzada en el desarrollo de nuestro modelo.

Dividir el conjunto de datos de entrenamiento para permitir la validación cruzada
set.seed ( 1234 ) 
subTrain  <-  createDataPartition ( y = formación $ classe , p = 0,75 , lista = FALSO )

TheTraining  <-  formación [ subTrain , ] 
TheTesting  <-  formación [ - subTrain , ]
Ddataset contiene 59 variables con la última columna que contiene la variable "clase" estamos tratando de predecir.

Modelprediction 1: Uso de árbol de decisión
modelDT  <-  rpart ( classe  ~ ., datos = TheTraining , método = "clase" )
predictionDT  <-  predecir ( modelDT , TheTesting , tipo  = "clase" )
Parcela de El árbol de decisiones
rpart.plot ( modelDT , principal = "Árbol de decisiones" , adicional = 102 , bajo = TRUE , faclen = 0 )


fancyRpartPlot  ( modelDT , principal = "árbol de decisión" )
## Advertencia: laboratorios no caben incluso en cex 0.15, puede haber algo de overplotting


Resultados del ensayo con nuestro conjunto de datos subTesting:
confusionMatrix ( predictionDT , TheTesting $ classe )
## Confusión Matrix y Estadísticas
## 
## Referencia
## Predicción ABCDE
## A 1235 157 16 50 20
## B 55 568 73 80 102
## C 44 125 690 118 116
## D 41 64 50 508 38
## E 20 35 26 48 625
## 
## Estadísticas generales
##                                           
## Precisión: 0.7394          
## IC del 95%: (0.7269, 0.7516)
## Sin información Rate: 0.2845          
## P-Value [Acc> NIR]: <2.2e-16       
##                                           
## Kappa: 0.6697          
## Prueba de P-Value de McNemar: <2.2e-16       
## 
## Estadísticas de la clase:
## 
## Clase: A Clase: B Clase: Clase C: D Clase: E
## Sensibilidad 0.8853 0.5985 0.8070 0.6318 0.6937
## Especificidad 0.9307 0.9216 0.9005 0.9529 0.9678
## Pos Pred Valor 0.8356 0.6469 0.6313 0.7247 0.8289
## Neg Pred Valor 0.9533 0.9054 0.9567 0.9296 0.9335
## Prevalencia 0.2845 0.1935 0.1743 0.1639 0.1837
## Tasa de detección 0.2518 0.1158 0.1407 0.1036 0.1274
Detección ## Prevalencia 0.3014 0.1790 0.2229 0.1429 0.1538
## Balanced Precisión 0.9080 0.7601 0.8537 0.7924 0.8307
La matriz de confusión alcanzó 0,7394% de precisión. Aquí, el IC del 95%: (0.7269, 0.7516). La estadística Kappa de 0.6697 refleja el error fuera de muestra. Para los valores anteriores es necesario utilizar el método determineis toRandom bosque modelo mucho mejor estimador y predictor.

Aplicado el Bosque Modelo aleatoria y se ha mostrado cantidad significativa de exactitud en la predicción. ### Modelprediction 2: Uso de Random Forest

modelRF  <-  randomForest ( classe  ~ ., datos = TheTraining , método = "clase" ) 
print  ( modelRF )
## 
## Llame al:
## RandomForest (fórmula = classe ~., Data = TheTraining, method = "clase") 
## Tipo de bosque al azar: la clasificación
## Número de árboles: 500
## Nº de variables intentó en cada división: 7
## 
## Estimación OOB de tasa de error: 0.43%
## Matriz de confusión:
## ABCDE class.error
## A 4182 2 0 0 1 0,0007168459
## B 14 2830 4 0 0 0,0063202247
## C 0 11 2553 3 0 0,0054538372
## D 0 0 18 2392 2 0,0082918740
## E 0 1 3 5 2697 0,0033259424
Predicción:
predictionRF  <-  predecir ( modelRF , TheTesting , tipo  =  "clase" )
Resultados del ensayo con conjunto de datos subTesting:
confusionMatrix ( predictionRF , TheTesting $ classe )
## Confusión Matrix y Estadísticas
## 
## Referencia
## Predicción ABCDE
## A 1394 3 0 0 0
## B 1 944 10 0 0
## C 0 2 843 6 0
## D 0 0 2 798 0
## E 0 0 0 0 901
## 
## Estadísticas generales
##                                           
## Precisión: 0.9951          
## IC del 95%: (0.9927, 0.9969)
## Sin información Rate: 0.2845          
## P-Value [Acc> NIR]: <2.2e-16       
##                                           
## Kappa: 0.9938          
## Prueba de P-Value de McNemar: NA              
## 
## Estadísticas de la clase:
## 
## Clase: A Clase: B Clase: Clase C: D Clase: E
## Sensibilidad 0.9993 0.9947 0.9860 0.9925 1.0000
## Especificidad 0.9991 0.9972 0.9980 0.9995 1.0000
## Pos Pred Valor 0.9979 0.9885 0.9906 0.9975 1.0000
## Neg Pred Valor 0.9997 0.9987 0.9970 0.9985 1.0000
## Prevalencia 0.2845 0.1935 0.1743 0.1639 0.1837
## Tasa de detección 0.2843 0.1925 0.1719 0.1627 0.1837
Detección ## Prevalencia 0.2849 0.1947 0.1735 0.1631 0.1837
## Balanced Precisión 0.9992 0.9960 0.9920 0.9960 1.0000
La matriz de confusión alcanzó 99,51% accuracy.in el IC del 95%: (0.9927, 0.9969) y el fuera de banda (Out-Of-Bag) Tasa de error es de 0,43% .El índice kappa de 0,9938 refleja el error fuera de muestra

Decisión
Como era de esperar, Random Bosque algoritmo funcionó mejor que árboles de decisión. Precisión para el modelo Random Forest era Precisión: 0.9951 y (IC del 95%: ((0.9927, 0.9969))) en comparación con IC del 95%: (0.7269, 0.7516) para el modelo de árbol de decisión. El modelo forestal se elige al azar. La precisión del modelo es 0,995. El error esperado fuera de la muestra se calculó en 0,005 o 0,5%. El error se esperaba fuera de la muestra se calcula como 1 - exactitud de las predicciones hechas contra el conjunto de validación cruzada. Nuestro conjunto de datos de prueba consta de 20 casos. Con una precisión superior al 99% en nuestros datos de validación cruzada, podemos esperar que muy pocos, o ninguno, de las muestras de ensayo se missclassified.

Conclusión
De los dos métodos de predicción utilizado en el estudio, la precisión era mejor método de método El Bosque aleatoria desde la matriz de confusión alcanza aproximadamente

Este modelo se utilizará para los cálculos finales es el proyecto.

la presentación. (Utilizando Coursera proporciona código)

Sumisión
answers <-  as.vector ( predictionRF [ 1 : 20 ] ) 
pml_write_files   =   function  (  x  )  {  
  n   =   length  (  x  )  
  for  (  i   in   1  :  n  )  {  
    filename   =   paste0  (  "problem_id_" , i , ".txt"  )  
    write.table  (  x  [  i  ] , file  =  filename , quote  =  FALSE , row.names  =  FALSE , col.names  =  FALSE  )  
  }  
}

pml_write_files  (  respuestas  )
